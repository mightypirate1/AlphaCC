services:
  trainer:
    image: alphacc/main
    build:
      dockerfile: Dockerfile.main
      target: main
    shm_size: '8gb'
    cpu_shares: 4096
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      keydb-main:
        condition: service_healthy
      keydb-pred:
        condition: service_healthy
    volumes:
      - local:/mnt:rw
    env_file:
      - .env.docker
    command: [
      "alphacc-trainer",
      "--run-id=lesgo-size9-0",
      "--size=9",
      "--tournament-freq=10",
      "--n-train-samples=5000",
      "--replay-buffer-size=30000",
      "--train-size=15000",
      "--epochs-per-update=5",
      "--policy-weight=1.0",
      "--value-weight=1.0",
      "--entropy-weight=0.01",
      "--l2-reg=3e-4",
      "--batch-size=128",
      "--lr=1e-4",
      "--gpu",
    ]

  worker:
    image: alphacc/main
    #cpu_shares: 256
    deploy:
      replicas: 40
    depends_on:
      - nn-service
    env_file:
      - .env.docker
    restart: always
    command: [
      "alphacc-worker",
      "--size=9",
      "--n-rollouts=init=100,step=20,min=0,max=3000",
      "--rollout-depth=init=10,step=3,max=100",
      "--action-temperature=init=1.3,step=-0.0015,min=0.01,max=1.0",
      "--max-game-length=init=275,random_add=50",
      "--dirichlet-noise-weight=0.15",
      "--rollout-gamma=0.99",
    ]

  nn-service:
    image: alphacc/main
    cpu_shares: 8192
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - trainer
    env_file:
      - .env.docker
    restart: always
    command: [
      "alphacc-nn-service",
      "--size=9",
      "--inference-batch-size=256",
      "--gpu",
    ]

  tensorboard:
    image: tensorflow/tensorflow
    network_mode: host
    depends_on:
      - trainer
    volumes:
      - local:/mnt:ro
    command:
      - "tensorboard"
      - "--logdir=/mnt/logdir"

  keydb-main:
    image: eqalpha/keydb
    cpu_shares: 256
    ports:
      - '6379:6379'
    command: [
      "keydb-server",
      "--appendonly", "no",
      "--save", "",
      "--server-threads", "2",
      "--tcp-backlog", "511",
      "--tcp-keepalive", "60",
      "--client-output-buffer-limit", "normal", "0", "0", "0",
      "--client-output-buffer-limit", "pubsub", "32mb", "8mb", "60",
    ]
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 5s
      timeout: 30s
      retries: 15
      start_period: 5s

  keydb-pred:
    image: eqalpha/keydb
    cpu_shares: 8192
    ports:
      - '6378:6379'
    command: [
      "keydb-server",
      "--appendonly", "no",
      "--save", "",
      "--server-threads", "16",
      "--tcp-backlog", "2048",
      "--tcp-keepalive", "60",
      "--io-threads", "8",
      "--maxclients", "1000",
      "--tcp-backlog", "2048",
      "--timeout", "3",
      "--client-output-buffer-limit", "normal", "0", "0", "0",
      "--client-output-buffer-limit", "pubsub", "64mb", "16mb", "240",
      "--maxmemory", "1gb",
      "--maxmemory-policy", "allkeys-lru",
      "--protected-mode", "no",
      "--dynamic-hz", "yes",
      "--hz", "100",
    ]
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 5s
      timeout: 30s
      retries: 15
      start_period: 5s

volumes:
  local:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "./data"
