services:
  trainer:
    image: alphacc/main
    build:
      dockerfile: Dockerfile.main
      target: main
    shm_size: '8gb'
    cpu_shares: 1024
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      keydb-main:
        condition: service_healthy
      keydb-pred:
        condition: service_healthy
    volumes:
      - local:/mnt:rw
    env_file:
      - .env.docker
    command: [
      "alphacc-trainer",
      # "--run-id=alpha-cc-size-5-run-00-gpu",
      "--run-id=dbg-10-size9",
      "--size=9",
      "--tournament-freq=30",
      "--n-train-samples=5000",
      "--replay-buffer-size=20000",
      "--train-size=10000",
      "--epochs-per-update=5",
      "--policy-weight=1.0",
      "--value-weight=1.0",
      "--entropy-weight=0.01",
      "--l2-reg=3e-4",
      "--batch-size=64",
      "--lr=1e-4",
      "--gpu",
    ]

  worker:
    image: alphacc/main
    cpu_shares: 2
    deploy:
      replicas: 20
    depends_on:
      - nn-service
    env_file:
      - .env.docker
    restart: always
    command: [
      "alphacc-worker",
      "--size=9",
      "--n-rollouts=1500",
      "--rollout-depth=200",
      "--max-game-length=300",
      "--dirichlet-noise-weight=0.15",
      "--rollout-gamma=0.99",
    ]
    
  nn-service:
    image: alphacc/main
    cpu_shares: 1024
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - trainer
    env_file:
      - .env.docker
    restart: always
    command: [
      "alphacc-nn-service",
      "--size=9",
      "--gpu",
      "--inference-batch-size=512",
    ]

  tensorboard:
    image: tensorflow/tensorflow
    network_mode: host
    depends_on:
      - trainer
    volumes:
      - local:/mnt:ro
    command:
      - "tensorboard"
      - "--logdir=/mnt/logdir"

  keydb-main:
    image: eqalpha/keydb
    ports:
      - '6379:6379'
    command: [
      "keydb-server",
      "--appendonly", "no",
      "--save", "",
      "--server-threads", "4",
      "--tcp-backlog", "511",
      "--tcp-keepalive", "60",
      "--client-output-buffer-limit", "normal", "0", "0", "0",
      "--client-output-buffer-limit", "pubsub", "32mb", "8mb", "60",
    ]
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 5s
      timeout: 30s
      retries: 15
      start_period: 5s

  keydb-pred:
    image: eqalpha/keydb
    ports:
      - '6378:6379'
    command: [
      "keydb-server",
      "--appendonly", "no",
      "--save", "",
      "--server-threads", "4",
      "--tcp-backlog", "511",
      "--tcp-keepalive", "60",
      "--client-output-buffer-limit", "normal", "0", "0", "0",
      "--client-output-buffer-limit", "pubsub", "32mb", "8mb", "60",
      "--maxmemory", "1gb",
      "--maxmemory-policy", "allkeys-lru",
      "--hz", "300",
    ]
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 5s
      timeout: 30s
      retries: 15
      start_period: 5s

volumes:
  local:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "./data"
